{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한눈에 보는 머신러닝\n",
    "## 머신러닝이란?\n",
    "- 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학. 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 한다.\n",
    "- training set(훈련 세트) 안에 training instance(훈련 사례)들이 존재. \n",
    "- 정확히 분류된 메일의 비율로 성능측정 가능. = 정확도 (accuracy)\n",
    "- 데이터마이닝(data mining) : 머신러닝 기술을 적용해 데이터 분석해 겉으로 보이지 않던 패턴 발견"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 시스템의 종류\n",
    "### 학습하는 동안의 감독형태나 정보량 따라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  지도학습(Supervised learning)\n",
    " - 훈련 데이터에 레이블(lable : 원하는 답)이 포함되어 있다.\n",
    "    1. 분류 (Classification) ex) 스팸필터\n",
    "    2. 회귀 (Regressoin) : 특성(예측변수) 이용해 타깃수치 예측\n",
    "    3. 로지스틱 회귀(logistic regression) : 클래스에 속할 확률 출력\n",
    "        \n",
    "        \n",
    " - 지도학습 알고리즘\n",
    "    \n",
    "    - k-최근접 이웃 (k-nearest neighbor)\n",
    "    - 선형회귀 (linear regression)\n",
    "    - 로지스틱 회귀 (logistic regression)\n",
    "    - 서포트 벡터 머신 (support vector machine)\n",
    "    - 결정트리 / 랜덤 포레스트 (decision tree / random forest)\n",
    "    - 신경망 (neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 비지도학습(Unsupervised learning) : 훈련데이터에 레이블이 없는 경우  \n",
    "  \n",
    "  - 비지도학습 알고리즘\n",
    "      1. 군집 (Clustering)\n",
    "          - k-평균 (k-means)\n",
    "          - DBSACN\n",
    "          - 계층군집분석 (hierarchical cluster analysis(HCA)) : 그룹을 더 작은 그룹으로 세분화\n",
    "          - 이상치 탐지 : 정상샘플 훈련, 새로운 샘플 판단 / 특이치 탐지 : 다른 샘플 탐지. 매우 깨끗한 훈련 세트 필요 (outlier detection / novelty detection)\n",
    "          - 원-클래스 (one-class SVM)\n",
    "          - 아이솔레이션 포레스트 (isolation forest)<br><br>\n",
    "      2. 시각화 (visualization) : 도식화 가능한 2D, 3D로 표현 / 차원축소 (dimensionality reduction) : 데이터 간소화 -> 상관관계 있는 여러 특성을 하나로 합치기 => 특성추출(feature extraction)\n",
    "          - 주성분 분석 (principal component analysis(PCA))\n",
    "          - 커널 (kernel PCA)\n",
    "          - 지역적 선형 임베딩 (locally-linear embedding(LLE))\n",
    "          - t-SNE (t-distrbuted stochastic neighbor embedding)<br><br>\n",
    "      3. 연관규칙학습 (association rule learning) : 대량 데이터에서 특성간의 흥미로운 관계 찾기\n",
    "          - 어프라이어리 (apriori)\n",
    "          - 이클렛 (Eclat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 준지도학습(semisupersived learning) : 일부만 레이블이 있는 데이터\n",
    " - ex) 구글포토 호스팅 서비스 : 지도학습(레이블) + 비지도 학습(군집)<br><br>\n",
    "\n",
    " - 심층 신뢰 신경망 (deep relief network(DBN)) : 여러 겹의 제한된 볼츠만 머신(restricted Boltzmann machine(RBM))에 기초. RBM 비지도 학습으로 순차학습 후 전체 시스템을 지도학습 방식으로 세밀히 조정\n",
    "<br><br>\n",
    " \n",
    "4) 강화학습(reinforcement learning)\n",
    " - 에이전트(학습하는 시스템) -> 환경관찰(environment) -> 행동실행(action) -> 보상/벌점(reward/penalty) -> 가장 큰 보상 얻기위한 정책(policy) 스스로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력데이터의 스트림(stream)으로부터 점진적 학습 가능한지의 여부에 따라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 배치학습 (batch learning) => 오프라인 학습\n",
    "\n",
    " - 시스템이 점진적학습을 하지 않는다.\n",
    " - 가용데이터 모두 사용해 훈련한다.\n",
    " - 시스템 훈련 후 추가학습 없이 적용된다.\n",
    " <br><br>\n",
    " - 새로운 데이터 학습시 새 데이터를 추가한 전체데이터 사용해 처음부터 다시 학습해야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 온라인 학습 (online learning)\n",
    " - 데이터를 순차적으로 한개씩 or 미니배치(mini-batch, 작은 묶음 단위)로 주입하여 시스템 학습\n",
    " - 매 학습단계 빠르고 비용 적게 듦\n",
    " - 시스템은 데이터 도착 즉시 학습 가능\n",
    " - 연속적으로 데이터 받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합. 컴퓨팅 자원 제한된 경우에도 좋다\n",
    " - 학습 끝난 데이터는 버려도 돼서 공간절약 가능\n",
    " <br><br>\n",
    " - 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 사용된다\n",
    "     - 외부메모리 out-of-core 학습 : 알고리즘이 데이터 일부 읽어들이고 훈련단계 수행. 전체데이터에 모두 적용될 때까지 과정 반복.\n",
    "     - = 점진적 학습(incremental learning). 보통 오프라인으로 실행. 실시간 시스템 학습하지 않는다.\n",
    "     \n",
    "- 학습률 learning rage : 변화하는 데이터에 얼마나 빠르게 적응할 것인가\n",
    " - 학습률 크면 : 데이터에 빠르게 적응. 예전 데이터 금방 잊어버림\n",
    " - 학습률 작으면 : 느리게 학습. 새로운 데이터 잡음이나 대표성 없는 데이터에 덜 민감하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어떻게 일반화(generalize) 되는가에 따라 분류\n",
    "- 일반화 : 훈련데이터가 아닌 새로운 데이터에서 좋은 예측을 얻는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 사례기반학습 (instance-based learning)\n",
    " - 유사도 측정 (similarity measure) : 시스템이 훈련 샘플 기억해 학습. 유사도 측정 사용해 새로운 데이터와 학습한 샘플(or 학습한 샘플 중 일부) 비교하는 식으로 일반화\n",
    " \n",
    "<br><br>\n",
    "2) 모델기반학습 (model-based learning) : 샘플들의 모델 만들어 예측(prediction)에 사용\n",
    " - 모델선택(model detection)\n",
    " - 측정지표(모델 성능 측정)\n",
    "     - 효용함수 (unility function) / 적합도함수 (fitness function) : 모델이 얼마나 좋은지 측정\n",
    "     - 비용함수 (cost function) : 보통 선형회귀에서 모델이 얼마나 나쁜지 측정. 예측과 훈련 데이터 사이의 거리 잼. 최소화 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형회귀 알고리즘\n",
    " - 모델훈련 : 알고리즘에 훈련데이터 공급. 데이터에 가장 잘 맞는 선형모델의 파라미터 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업 요약\n",
    "\n",
    "1. 데이터 분석\n",
    "2. 모델 선택\n",
    "3. 훈련데이터 -> 모델훈련\n",
    "4. 추론(새로운 데이터에 모델적용, 예측). 잘 일반화 되도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝의 주요 도전 과제\n",
    "### 나쁜 데이터 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "2) 대표성 없는 훈련 데이터\n",
    " - 샘플링 잡음 (sampling noise) :  샘플 작음. 우연에 의한 대표성 없는 데이터\n",
    " - 샘플링 편향 (sampling bias) : 매우 크지만 표본 추출 방법 잘못돼 대표성 없음.\n",
    "     - 비응답편향 (nonreponse bias)\n",
    "     \n",
    "3) 낮은 품질의 데이터 : 에러, 이상치(outlier), 잡음 많은 데이터\n",
    " - 훈련 데이터 정제가 필요한 경우\n",
    "     1. 일부 샘플이 명확한 이상치 -> 무시하거나 수동으로 수정\n",
    "     2. 일부 샘플에 특성 몇개 빠진 경우 -> 특성 모두 무시 / 샘플 무시 / 결측치 보정 / 특성 넣은 모델과 제외한 모델 따로 훈련\n",
    "     \n",
    "4) 관련없는 특성\n",
    " - 특성공학 (feature engineering) : 훈련에 사용할 좋은 특성 찾기\n",
    "     1. 특성 선택 (feature selection) : 가지고 있는 특성 중 훈련에 가장 유용한 특성 선택\n",
    "     2. 특성 추출 (feature extraction) : 특성 결합해 더 유용한 특성 만듦. ex) 차원축소알고리즘\n",
    "     3. 새로운 데이터 수집해 새 특성 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나쁜 알고리즘 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 훈련 데이터 과대적합(overfitting)\n",
    " - 과대적합 (overfitting) : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐.\n",
    " - 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생\n",
    " <br><br>\n",
    " - 해결 방법\n",
    "     - 파라미터 수가 적은 모델 선택 / 훈련 데이터에 있는 특성 수 줄이기 / 모델에 제약 가해 단순화\n",
    "     - 훈련 데이터 더 많이 수집\n",
    "     - 훈련 데이터의 잡음 줄이기 (오류 데이터 수정/이상치 제거 등)\n",
    " <br><br>\n",
    " - 규제(regularization) : 모델에 제약을 가해 모델을 단순하게 하는 것\n",
    "     - ex) 선형 모델이 두 개의 파라미터 가질 때, 훈련 데이터에 모델을 맞추기 위한 두 개의 자유도(degree of freedom)을 학습 알고리즘에 부여\n",
    "     - 데이터에 완벽히 맞추는 것과 일반화를 위해 단순한 모델을 유지하는 것 사이의 올바른 균형 찾을 것\n",
    " <br><br>\n",
    " - 하이퍼파라미터(hyperparameter) : 학습 알고리즘의 파라미터.\n",
    "     - 학습하는 동안 적용할 규제의 양 결정\n",
    "     - 학습 알고리즘으로부터 영향 받지 않음\n",
    "     - 훈련 전에 미리 지정되고, 훈련하는 동안 상수로 남음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 훈련 데이터 과소적합(underfitting)\n",
    " - 과소적합(underfitting) : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생\n",
    "<br><br>\n",
    " - 해결 방법\n",
    "      - 모델 파라미터가 더 많은 강력한 모델 선택\n",
    "      - 학습 알고리즘에 더 좋은 특성 제공(특성 공학)\n",
    "      - 모델의 제약 줄이기(ex) 규제 하이퍼 파라미터 감소)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트와 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 훈련 데이터 -> 훈련 세트 / 데이터 세트 두개로 나누기\n",
    " - 훈련 세트를 사용해 모델 훈련, 데이터 세트를 사용해 모델 테스트\n",
    " - 일반화 오차(generalization error) / 외부 샘플 오차(out-of-sample error) : 새로운 샘플에 대한 오류 비율\n",
    " - 테스트 세트에서 모델 평가하면서 이 오차에 대한 추정값(estimation) 얻음\n",
    " <br><br>\n",
    " - 훈련 오차 낮지만 일반화 오차 높으면 모델이 훈련데이터에 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 하이퍼파라미터 튜닝\n",
    " - 홀드아웃 검증(holdout validation) : 훈련 세트의 일부 떼어내어 여러 후보 모델 평가하고 가장 좋은 것 선택.\n",
    "     - 새로운 홀드아웃 세트 = 검증 세트(validation set)/개발 세트(developement set)/데브 세트(dev set)\n",
    "     1. 훈련세트(전체 훈련 세트 - 검증 세트)에서 다양한 하이퍼파라미터 값 가진 여러 모델 훈련\n",
    "     2. 검증 세트에서 가장 높은 성능 내는 모델 선택\n",
    "     3. 홀드아웃 검증 과정 끝나면 이 최선의 모델을 전체훈련세트에서 다시 훈련해 최종 모델 만듦\n",
    "     4. 최종 모델을 테스트 세트에서 평가해 일반화 오차 측정\n",
    "     <br><br>\n",
    " - 검증 세트가 너무 작거나 크면 문제 발생\n",
    " - 이를 해결하기 위해 교차검증 수행\n",
    "     - 교차검증(cross-validation) : 작은 검증 세트를 여러개 사용해 반복적으로 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 데이터 불일치\n",
    " - 가장 중요한 규칙 : 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 한 잘 대표해야 한다.\n",
    " - => 검증 세트와 테스트 세트에 대표 사진이 대표적으로 포함되어 있어야 함\n",
    " <br><br>\n",
    " - 훈련-개발 세트(train-dev set)\n",
    "     - 검증 세트와 테스트 세트를 반반. 웹에서 다운로드한 훈련 사진의 일부를 떼어내서 또 다른 세트를 만든다.\n",
    "     - 모델이 잘 작동하면 훈련 세트에 과대적합된 것이 아님\n",
    "     - 모델이 검증 세트에서 나쁜 성능을 내면 데이터 불일치 때문\n",
    "     - 웹 이미지를 전처리한 후 모델을 다시 훈련해 문제 해결\n",
    "     - 모델이 훈련-개발 세트에서 잘 작동하지 않으면 훈련 세트 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
